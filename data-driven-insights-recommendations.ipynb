{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30702,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data Driven Insights","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Dominance of Low Truth Ratings: The pie chart demonstrates that a large portion of the dataset consists of articles with a TruthRating of 0. This suggests that the data is skewed toward fake news or articles with low credibility, providing a robust dataset for training a fake news detection model.\n\n    \nArticle Distribution by Country: The histogram on the number of articles per country shows a significant skew toward American articles compared to Indian ones. This imbalance indicates that any analysis or models developed may have a US-centric bias. From our Heatmap and our HIstogram of average truthrating per subject, we can also see that in the realm of US governmental news, people should be more wary of fake news, due to the high amount of articles relating to the US government, and their average truth rating being just above 1.0\n\n    \nFake News Distribution by Country: The dual-variable histogram reveals that American articles have a higher proportion of TruthRating 0 compared to Indian articles, which show a more balanced distribution. This suggests a potentially higher prevalence of fake news in American sources.\n\n    \nGovernment Articles and Low Truth Ratings: The heatmap shows that the number of US governmental articles far exceeds other country and subject combinations. The subsequent histogram indicates that these articles tend to have lower TruthRatings, supporting the hypothesis that many government-related articles in the US are less credible.\n\n    \nCommon Words in Fake News: The word cloud, focused on TruthRatings 0, 1, and 2, identifies frequently used words in low-truth articles. Terms like \"Fact Check\", \"new\", \"say\", \"look\", \"people\", and \"found\" are among the most prominent, suggesting common linguistic patterns in fake news.","metadata":{"execution":{"iopub.status.busy":"2024-04-24T15:03:11.601632Z","iopub.execute_input":"2024-04-24T15:03:11.602022Z","iopub.status.idle":"2024-04-24T15:03:11.643588Z","shell.execute_reply.started":"2024-04-24T15:03:11.601990Z","shell.execute_reply":"2024-04-24T15:03:11.642166Z"}}},{"cell_type":"markdown","source":"## Recommendations","metadata":{}},{"cell_type":"markdown","source":"Focus on High-Risk Sources: Given the high prevalence of low-truth articles in American sources, prioritize monitoring and fact-checking for news originating from these sources. Develop specific algorithms or filters to detect common patterns in these articles.\n\n\nAddress Data Imbalance: Since the dataset is heavily skewed toward low TruthRatings and American articles, consider techniques to balance the data. This could involve under-sampling or over-sampling to ensure that machine learning models do not become biased.\n\n\nSubject-Specific Fact-Checking: With government-related articles showing a significant number of low TruthRatings, establish fact-checking protocols specific to government news. This can improve the credibility of political and governmental information.\n\n\nUse Common Words to Detect Fake News: Incorporate word cloud insights into fake news detection algorithms. Focus on words that frequently appear in low-truth articles to create linguistic patterns that help detect fake news. Also, we notice a clear and obvious trend to be very careful of articles with buzzwords such as “Fact Check”, “new”, “say”, “look”, “people” and “found”. One can further deduce fake news articles may include phrases made up of some of these words. An example be \"People say\" or \"New _ found\"\n\n\nCross-Country Analysis for Better Generalization: The skew toward American sources may limit the generalizability of findings. Expand the dataset to include more diverse geographical sources to ensure models can detect fake news across different cultural and national contexts.\n\n\nEnhance Public Awareness: The insights gained from these analyses can be used to educate the public about the prevalence of fake news and common signs to look out for. Promote media literacy to help individuals critically evaluate news sources.","metadata":{"execution":{"iopub.status.busy":"2024-04-24T15:03:51.195662Z","iopub.execute_input":"2024-04-24T15:03:51.196363Z","iopub.status.idle":"2024-04-24T15:03:51.206191Z","shell.execute_reply.started":"2024-04-24T15:03:51.196328Z","shell.execute_reply":"2024-04-24T15:03:51.204642Z"}}}]}