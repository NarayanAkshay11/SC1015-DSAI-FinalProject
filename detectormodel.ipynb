{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":8215614,"datasetId":4823751,"databundleVersionId":8340627}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Creating the Fake News Detection Model using Machine Learning & Neural Networks","metadata":{}},{"cell_type":"markdown","source":"##### In this notebook we will be comparing ML and DL techniques to figure which of them give the best accuracy for a Fake News Detector","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-24T13:48:40.284123Z","iopub.execute_input":"2024-04-24T13:48:40.284465Z","iopub.status.idle":"2024-04-24T13:48:40.299960Z","shell.execute_reply.started":"2024-04-24T13:48:40.284441Z","shell.execute_reply":"2024-04-24T13:48:40.299160Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/input/sc1015dsai-final-fce2-team-1-23-24/categories_one.csv\n/kaggle/input/sc1015dsai-final-fce2-team-1-23-24/final.csv\n/kaggle/input/sc1015dsai-final-fce2-team-1-23-24/with_subject.csv\n/kaggle/input/sc1015dsai-final-fce2-team-1-23-24/no_subject.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sc1015dsai-final-fce2-team-1-23-24/final.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T13:48:40.301446Z","iopub.execute_input":"2024-04-24T13:48:40.301673Z","iopub.status.idle":"2024-04-24T13:48:41.385480Z","shell.execute_reply.started":"2024-04-24T13:48:40.301653Z","shell.execute_reply":"2024-04-24T13:48:41.384315Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T13:48:41.387219Z","iopub.execute_input":"2024-04-24T13:48:41.387526Z","iopub.status.idle":"2024-04-24T13:48:41.407566Z","shell.execute_reply.started":"2024-04-24T13:48:41.387505Z","shell.execute_reply":"2024-04-24T13:48:41.406257Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"         TruthRating\ncount  361363.000000\nmean        1.357978\nstd         1.900495\nmin         0.000000\n25%         0.000000\n50%         0.000000\n75%         2.000000\nmax         5.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TruthRating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>361363.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.357978</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.900495</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Removing null values (if any)","metadata":{}},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T13:48:41.408905Z","iopub.execute_input":"2024-04-24T13:48:41.409260Z","iopub.status.idle":"2024-04-24T13:48:41.512522Z","shell.execute_reply.started":"2024-04-24T13:48:41.409231Z","shell.execute_reply":"2024-04-24T13:48:41.511601Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T13:48:41.514631Z","iopub.execute_input":"2024-04-24T13:48:41.514925Z","iopub.status.idle":"2024-04-24T13:48:41.526580Z","shell.execute_reply.started":"2024-04-24T13:48:41.514901Z","shell.execute_reply":"2024-04-24T13:48:41.525627Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                Text   Subject  TruthRating  \\\n0  WHO praises India's Aarogya Setu app, says it ...  COVID-19            5   \n1  In Delhi, Deputy US Secretary of State Stephen...  VIOLENCE            5   \n2  LAC tensions: China's strategy behind delibera...    TERROR            5   \n3  India has signed 250 documents on Space cooper...  COVID-19            5   \n4  Tamil Nadu chief minister's mother passes away...  ELECTION            5   \n\n  Country                                         clean_text  \n0   India  praises india aarogya setu app says helped ide...  \n1   India  delhi deputy us secretary state stephen biegun...  \n2   India  lac tensions china strategy behind deliberatel...  \n3   India  india signed documents space cooperation count...  \n4   India       tamil nadu chief minister mother passes away  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Subject</th>\n      <th>TruthRating</th>\n      <th>Country</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WHO praises India's Aarogya Setu app, says it ...</td>\n      <td>COVID-19</td>\n      <td>5</td>\n      <td>India</td>\n      <td>praises india aarogya setu app says helped ide...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>In Delhi, Deputy US Secretary of State Stephen...</td>\n      <td>VIOLENCE</td>\n      <td>5</td>\n      <td>India</td>\n      <td>delhi deputy us secretary state stephen biegun...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LAC tensions: China's strategy behind delibera...</td>\n      <td>TERROR</td>\n      <td>5</td>\n      <td>India</td>\n      <td>lac tensions china strategy behind deliberatel...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>India has signed 250 documents on Space cooper...</td>\n      <td>COVID-19</td>\n      <td>5</td>\n      <td>India</td>\n      <td>india signed documents space cooperation count...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Tamil Nadu chief minister's mother passes away...</td>\n      <td>ELECTION</td>\n      <td>5</td>\n      <td>India</td>\n      <td>tamil nadu chief minister mother passes away</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Creating a function to train and test ML model (Linear Regression)","metadata":{}},{"cell_type":"markdown","source":"#### Linear regression is a foundational algorithm in the field of machine learning and statistics. It is used to model the relationship between a dependent variable (also known as the target or outcome) and one or more independent variables (also known as predictors, features, or explanatory variables)\n\n#### Random Forest is a robust ensemble learning algorithm widely used in machine learning tasks, especially in classification and regression problems.Random Forest uses an ensemble of multiple decision trees to make predictions.Bagging is a technique used in Random Forest to create different datasets for training each tree","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression #Importing the ML model\nfrom sklearn.model_selection import train_test_split #To split data into training and testing sets\nfrom sklearn.metrics import accuracy_score, f1_score #Accuracy and F1 Score are 2 evaluation Metrics\nfrom sklearn.feature_extraction.text import CountVectorizer #To convert string into vectors for computation\nimport matplotlib.pyplot as plt #For visualization, if any\n\ndef logistic_regression(df):    \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(df['clean_text']) #getting the vectorized data.\n    #Splitting data into testing and training sets\n    X_train, X_test, y_train, y_test = train_test_split(X, df['TruthRating'], test_size=0.2, random_state=42)\n    \n    #Initializing & Fitting the ML Model\n    model = LogisticRegression(max_iter = 500) #Max interations = 500\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test) #Obtaining predictions  \n    test_accuracy = accuracy_score(y_test, y_pred) #Testing Accuracy\n    print(\"F1 Score: \",f1_score(y_test, y_pred, average='weighted')) #Getting F1 score, see below\n    print(model, test_accuracy)\n\ndef random_forest(df):    \n    vectorizer = CountVectorizer()\n    X_train, X_test, y_train, y_test = train_test_split(df[['Text', 'Subject', 'Country']], df['TruthRating'], test_size=0.2, random_state=42)    \n    X_train_v = vectorizer.fit_transform(X_train['Text'])\n    X_test_v = vectorizer.transform(X_test['Text'])\n    \n    rf = RandomForestClassifier(n_estimators=50, random_state=42) #More the estimators, better the accuracy\n    rf.fit(X_train_v, y_train)\n    \n    y_pred = rf.predict(X_test_v)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Test Accuracy: {accuracy:.2f}\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-24T13:48:41.527558Z","iopub.execute_input":"2024-04-24T13:48:41.527800Z","iopub.status.idle":"2024-04-24T13:48:41.537305Z","shell.execute_reply.started":"2024-04-24T13:48:41.527779Z","shell.execute_reply":"2024-04-24T13:48:41.536208Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### The F1 score is a metric commonly used in binary classification tasks to evaluate the performance of a model. It combines precision and recall into a single value. The F1 score is the harmonic mean of precision and recall.\n\n##### Precision measures the proportion of true positive predictions (correctly classified positive instances) out of all positive predictions made by the model. \n\n##### Recall measures the proportion of true positive predictions out of all actual positive instances in the data. \n","metadata":{}},{"cell_type":"code","source":"logistic_regression(df)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T13:48:41.538485Z","iopub.execute_input":"2024-04-24T13:48:41.538773Z","iopub.status.idle":"2024-04-24T13:50:26.516646Z","shell.execute_reply.started":"2024-04-24T13:48:41.538750Z","shell.execute_reply":"2024-04-24T13:50:26.515948Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"F1 Score:  0.7623939920103936\nLogisticRegression(max_iter=500) 0.777351911555119\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Neural Networks","metadata":{}},{"cell_type":"markdown","source":"### Neural networks are a type of machine learning algorithm inspired by the structure and functioning of the human brain. A neural network consists of interconnected nodes (neurons) organized into layers. Each neuron takes inputs, applies a transformation (such as a weighted sum), and produces an output. The key elements of neural networks include:\n\n#### Layers: Neural networks consist of an input layer, one or more hidden layers, and an output layer. Hidden layers can include various transformations, like dense layers (fully connected), convolutional layers, recurrent layers, etc.\n\n#### Weights and Biases: Each connection between neurons has an associated weight, and each neuron has a bias. These parameters are adjusted during training to optimize the network's performance.\n#### Activation Functions: After applying the weighted sum and bias, activation functions introduce non-linearity to the network. Common activation functions include ReLU (Rectified Linear Unit), sigmoid, and softmax.\n\n#### Training: Neural networks are typically trained using a process called backpropagation, which involves calculating gradients of a loss function with respect to the weights and updating them to minimize the loss.","metadata":{}},{"cell_type":"markdown","source":"**Considering the number of datapoints (nearly 300,000), the neural network takes around 30 minutes for 7 epochs to get completed at optimal capacity **","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\n\nX_train, X_test, y_train, y_test = train_test_split(df[['Text', 'Subject', 'Country']], df['TruthRating'], test_size=0.2, random_state=42)\nmax_words = 10000 \n\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(X_train[\"Text\"])\nX_train_seq = tokenizer.texts_to_sequences(X_train[\"Text\"])\nX_test_seq = tokenizer.texts_to_sequences(X_test[\"Text\"])\n\n\nmax_len = 100 \nX_train_padded = pad_sequences(X_train_seq, maxlen=max_len)\nX_test_padded = pad_sequences(X_test_seq, maxlen=max_len)\n\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n\nembedding_dim = 100\nmodel = Sequential()\nmodel.add(Embedding(max_words, embedding_dim))\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(6, activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nbatch_size = 32 \nepochs = 7  #Thala For a reason\nmodel.fit(X_train_padded, y_train_encoded, batch_size=batch_size, epochs=epochs, validation_data=(X_test_padded, y_test_encoded))\n\nloss, accuracy = model.evaluate(X_test_padded, y_test_encoded)\nprint(f'Test Loss: {loss}, Test Accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T13:50:26.519831Z","iopub.execute_input":"2024-04-24T13:50:26.521536Z","iopub.status.idle":"2024-04-24T15:30:08.982388Z","shell.execute_reply.started":"2024-04-24T13:50:26.521508Z","shell.execute_reply":"2024-04-24T15:30:08.981352Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/7\n\u001b[1m9034/9034\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m846s\u001b[0m 93ms/step - accuracy: 0.7589 - loss: 0.7265 - val_accuracy: 0.8248 - val_loss: 0.5152\nEpoch 2/7\n\u001b[1m9034/9034\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m841s\u001b[0m 93ms/step - accuracy: 0.8413 - loss: 0.4670 - val_accuracy: 0.8360 - val_loss: 0.4838\nEpoch 3/7\n\u001b[1m9034/9034\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m841s\u001b[0m 93ms/step - accuracy: 0.8624 - loss: 0.4019 - val_accuracy: 0.8393 - val_loss: 0.4759\nEpoch 4/7\n\u001b[1m9034/9034\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m853s\u001b[0m 92ms/step - accuracy: 0.8807 - loss: 0.3496 - val_accuracy: 0.8381 - val_loss: 0.4808\nEpoch 5/7\n\u001b[1m9034/9034\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m825s\u001b[0m 91ms/step - accuracy: 0.8933 - loss: 0.3144 - val_accuracy: 0.8398 - val_loss: 0.4984\nEpoch 6/7\n\u001b[1m9034/9034\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m825s\u001b[0m 91ms/step - accuracy: 0.9031 - loss: 0.2831 - val_accuracy: 0.8391 - val_loss: 0.5146\nEpoch 7/7\n\u001b[1m9034/9034\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m869s\u001b[0m 92ms/step - accuracy: 0.9115 - loss: 0.2586 - val_accuracy: 0.8353 - val_loss: 0.5389\n\u001b[1m2259/2259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 30ms/step - accuracy: 0.8352 - loss: 0.5380\nTest Loss: 0.5389291048049927, Test Accuracy: 0.835258960723877\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"markdown","source":"### Since the Neural Network has a accuracy of 0.835 which is considered to be much better as compared to the 0.77 by the Linear Regressor,the neural network is a much better model to detect Fake News as compared to Linear Regressor","metadata":{}},{"cell_type":"markdown","source":"But if we factor in computational costs, the NN got the accuracy after 7 epochs which is quite expensive as compared to the Linear Regressor. But if general accuracy is what is mostly required (in the case of Fake News Detection, it is), then neural networks make a very good choice.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}